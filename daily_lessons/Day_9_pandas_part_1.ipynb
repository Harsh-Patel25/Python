{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNCtdfYeUxMNfLQtmbP+NJb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harsh-Patel25/Python/blob/main/daily_lessons/Day_9_pandas_part_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  **ðŸ“š <span style=\"color:red\">Dayâ€‘9 Lesson: Python Pandas Tutorials â€“ Part 1</span> ðŸš€**\n",
        "\n",
        "> **Pandas** is a powerful library for data manipulation and analysis. It provides two primary data structures: **DataFrame** (a table-like structure) and **Series** (a one-dimensional labeled array). Pandas makes it easy to work with structured data.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Installation and Importing Pandas\n",
        "\n",
        "Before you can use Pandas, you must install it (if not already installed) and then import it.  \n",
        "> **Command:**  \n",
        "```bash\n",
        "!pip install pandas\n",
        "```\n",
        "\n",
        "> **In Python:**  \n",
        "```python\n",
        "import pandas as pd\n",
        "import numpy as np  # We often use NumPy to create data for Pandas\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Creating a DataFrame\n",
        "\n",
        "### 2.1 Using NumPy Arrays\n",
        "\n",
        "You can create a DataFrame from a NumPy array. For example, consider a simple array created by reshaping a range of numbers:\n",
        "\n",
        "```python\n",
        "# Create a NumPy array of shape (5,4)\n",
        "data = np.arange(0, 20).reshape(5, 4)\n",
        "print(data)\n",
        "```\n",
        "\n",
        "> **Output:**  \n",
        "```\n",
        "array([[ 0,  1,  2,  3],\n",
        "       [ 4,  5,  6,  7],\n",
        "       [ 8,  9, 10, 11],\n",
        "       [12, 13, 14, 15],\n",
        "       [16, 17, 18, 19]])\n",
        "```\n",
        "\n",
        "Now create a DataFrame with custom row and column labels:\n",
        "\n",
        "```python\n",
        "df = pd.DataFrame(data=data,\n",
        "                  index=[\"Row1\", \"Row2\", \"Row3\", \"Row4\", \"Row5\"],\n",
        "                  columns=[\"Column1\", \"Column2\", \"Column3\", \"Column4\"])\n",
        "```\n",
        "\n",
        "### **Extra Examples for DataFrame Creation:**\n",
        "\n",
        "1. **From a Dictionary:**\n",
        "   ```python\n",
        "   data_dict = {\n",
        "       \"Name\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
        "       \"Age\": [25, 30, 35],\n",
        "       \"City\": [\"New York\", \"Los Angeles\", \"Chicago\"]\n",
        "   }\n",
        "   df_dict = pd.DataFrame(data_dict)\n",
        "   print(df_dict)\n",
        "   ```\n",
        "2. **From a List of Dictionaries:**\n",
        "   ```python\n",
        "   data_list = [\n",
        "       {\"A\": 1, \"B\": 2},\n",
        "       {\"A\": 3, \"B\": 4},\n",
        "       {\"A\": 5, \"B\": 6}\n",
        "   ]\n",
        "   df_list = pd.DataFrame(data_list)\n",
        "   print(df_list)\n",
        "   ```\n",
        "3. **Empty DataFrame and then Adding Data:**\n",
        "   ```python\n",
        "   df_empty = pd.DataFrame(columns=[\"X\", \"Y\", \"Z\"])\n",
        "   df_empty.loc[0] = [10, 20, 30]\n",
        "   df_empty.loc[1] = [40, 50, 60]\n",
        "   print(df_empty)\n",
        "   ```\n",
        "4. **Using np.arange with reshape (Different dimensions):**\n",
        "   ```python\n",
        "   arr = np.arange(12).reshape(3, 4)\n",
        "   df_from_arr = pd.DataFrame(arr, columns=[\"C1\", \"C2\", \"C3\", \"C4\"])\n",
        "   print(df_from_arr)\n",
        "   ```\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Viewing and Exploring the DataFrame\n",
        "\n",
        "### 3.1 Using Head, Tail, Type, Info, and Describe\n",
        "\n",
        "- **`df.head()`**: Shows the first 5 rows by default.\n",
        "- **`df.tail()`**: Shows the last 5 rows.\n",
        "- **`type(df)`**: Tells you the type of the object (should be `<class 'pandas.core.frame.DataFrame'>`).\n",
        "- **`df.info()`**: Displays a concise summary including data types and non-null counts.\n",
        "- **`df.describe()`**: Provides summary statistics for numeric columns.\n",
        "\n",
        "```python\n",
        "print(\"DataFrame Head:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nDataFrame Tail:\")\n",
        "print(df.tail())\n",
        "\n",
        "print(\"\\nDataFrame Type:\")\n",
        "print(type(df))\n",
        "\n",
        "print(\"\\nDataFrame Info:\")\n",
        "df.info()\n",
        "\n",
        "print(\"\\nDataFrame Description:\")\n",
        "print(df.describe())\n",
        "```\n",
        "\n",
        "### **Extra Examples:**\n",
        "\n",
        "1. **Using `df.shape` to check dimensions:**\n",
        "   ```python\n",
        "   print(\"Shape of DataFrame:\", df.shape)\n",
        "   ```\n",
        "2. **Checking Column Data Types:**\n",
        "   ```python\n",
        "   print(\"Data types:\\n\", df.dtypes)\n",
        "   ```\n",
        "3. **Customizing `head()` (e.g., first 3 rows):**\n",
        "   ```python\n",
        "   print(\"First 3 rows:\\n\", df.head(3))\n",
        "   ```\n",
        "4. **Summary for Non-Numeric Data:**\n",
        "   ```python\n",
        "   # For a DataFrame with string data:\n",
        "   df_str = pd.DataFrame({\"Name\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
        "                          \"City\": [\"NY\", \"LA\", \"CHI\"]})\n",
        "   print(df_str.describe(include=[object]))\n",
        "   ```\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Indexing and Selecting Data\n",
        "\n",
        "### 4.1 Column Selection\n",
        "\n",
        "- **Single Column as a Series:**  \n",
        "  ```python\n",
        "  col1 = df['Column1']\n",
        "  print(\"Type of df['Column1']:\", type(col1))\n",
        "  ```\n",
        "  \n",
        "- **Multiple Columns:**  \n",
        "  ```python\n",
        "  subset_df = df[['Column1', 'Column2', 'Column3']]\n",
        "  print(subset_df)\n",
        "  ```\n",
        "\n",
        "### 4.2 Row Selection using `loc` and `iloc`\n",
        "\n",
        "- **Using `loc` (Label-based):**\n",
        "  ```python\n",
        "  # Select rows with labels Row3 and Row4\n",
        "  rows_loc = df.loc[['Row3', 'Row4']]\n",
        "  print(\"Rows selected using loc:\\n\", rows_loc)\n",
        "  ```\n",
        "\n",
        "- **Using `iloc` (Integer-location based):**\n",
        "  ```python\n",
        "  # Select rows by index positions, e.g., 2nd and 3rd rows (index 2 and 3)\n",
        "  rows_iloc = df.iloc[2:4, 0:2]\n",
        "  print(\"Rows selected using iloc:\\n\", rows_iloc)\n",
        "  ```\n",
        "\n",
        "### **Extra Examples for Indexing:**\n",
        "\n",
        "1. **Selecting a Single Cell:**\n",
        "   ```python\n",
        "   cell_value = df.loc[\"Row3\", \"Column3\"]\n",
        "   print(\"Value at Row3, Column3:\", cell_value)\n",
        "   ```\n",
        "2. **Boolean Indexing (Filtering):**\n",
        "   ```python\n",
        "   # Filter rows where Column2 is greater than 2\n",
        "   filtered_df = df[df['Column2'] > 2]\n",
        "   print(\"Filtered DataFrame:\\n\", filtered_df)\n",
        "   ```\n",
        "3. **Selecting with `iloc` for all rows and columns 1 and 2:**\n",
        "   ```python\n",
        "   subset_iloc = df.iloc[:, 1:3]\n",
        "   print(\"Subset using iloc (columns 1-2):\\n\", subset_iloc)\n",
        "   ```\n",
        "4. **Using `loc` for range selection:**\n",
        "   ```python\n",
        "   # Assuming your index is labeled, select from Row2 to Row4:\n",
        "   range_loc = df.loc[\"Row2\":\"Row4\"]\n",
        "   print(\"Rows from Row2 to Row4:\\n\", range_loc)\n",
        "   ```\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Converting DataFrame into Arrays\n",
        "\n",
        "You can convert parts of your DataFrame into a NumPy array using the `.values` attribute (or `.to_numpy()` in newer versions).\n",
        "\n",
        "```python\n",
        "array_from_df = df.iloc[:, 1:].values\n",
        "print(\"DataFrame converted to array:\\n\", array_from_df)\n",
        "```\n",
        "\n",
        "### **Extra Examples:**\n",
        "\n",
        "1. **Converting a single column to array:**\n",
        "   ```python\n",
        "   col_array = df['Column1'].to_numpy()\n",
        "   print(\"Column1 as array:\", col_array)\n",
        "   ```\n",
        "2. **Converting the entire DataFrame:**\n",
        "   ```python\n",
        "   full_array = df.to_numpy()\n",
        "   print(\"Entire DataFrame as array:\\n\", full_array)\n",
        "   ```\n",
        "3. **Reshaping converted array:**\n",
        "   ```python\n",
        "   reshaped_array = full_array.reshape(4, 5)  # Only if total elements allow this shape\n",
        "   print(\"Reshaped array:\\n\", reshaped_array)\n",
        "   ```\n",
        "4. **Using `.values` vs `.to_numpy()`:**  \n",
        "   Both work similarly. Example:\n",
        "   ```python\n",
        "   array_via_values = df.values\n",
        "   array_via_to_numpy = df.to_numpy()\n",
        "   print(\"Using .values:\\n\", array_via_values)\n",
        "   print(\"Using .to_numpy():\\n\", array_via_to_numpy)\n",
        "   ```\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Basic Operations on DataFrames\n",
        "\n",
        "### 6.1 Handling Missing Data and Nulls\n",
        "\n",
        "- **Check for nulls:**\n",
        "  ```python\n",
        "  print(\"Null counts:\\n\", df.isnull().sum())\n",
        "  ```\n",
        "  \n",
        "- **Boolean result for non-null columns:**\n",
        "  ```python\n",
        "  print(\"Non-null indicator:\\n\", df.isnull().sum() == 0)\n",
        "  ```\n",
        "\n",
        "### **Extra Examples:**\n",
        "\n",
        "1. **Filling missing values:**\n",
        "   ```python\n",
        "   df_filled = df.fillna(0)\n",
        "   print(\"DataFrame after filling nulls:\\n\", df_filled)\n",
        "   ```\n",
        "2. **Dropping rows with missing values:**\n",
        "   ```python\n",
        "   df_dropped = df.dropna()\n",
        "   print(\"DataFrame after dropping nulls:\\n\", df_dropped)\n",
        "   ```\n",
        "3. **Count missing values for each column in a DataFrame created with NaNs:**\n",
        "   ```python\n",
        "   df_nan = pd.DataFrame([[1, np.nan, 2], [1, 3, 4]],\n",
        "                         index=[\"Row1\", \"Row2\"],\n",
        "                         columns=[\"Column1\", \"Column2\", \"Column3\"])\n",
        "   print(\"Null counts in df_nan:\\n\", df_nan.isnull().sum())\n",
        "   ```\n",
        "4. **Using boolean indexing to filter rows without nulls:**\n",
        "   ```python\n",
        "   df_no_nulls = df_nan[df_nan.notnull().all(axis=1)]\n",
        "   print(\"Rows with no nulls:\\n\", df_no_nulls)\n",
        "   ```\n",
        "\n",
        "### 6.2 Aggregation and Value Counts\n",
        "\n",
        "- **Value Counts:**\n",
        "  ```python\n",
        "  # For a given column in a DataFrame\n",
        "  print(\"Value counts for Column3:\")\n",
        "  print(df['Column3'].value_counts())\n",
        "  ```\n",
        "\n",
        "- **Unique Values:**\n",
        "  ```python\n",
        "  print(\"Unique values in Column2:\", df['Column2'].unique())\n",
        "  ```\n",
        "\n",
        "- **Filtering DataFrame with conditions:**\n",
        "  ```python\n",
        "  filtered_condition = df[df['Column2'] > 2]\n",
        "  print(\"Rows where Column2 > 2:\\n\", filtered_condition)\n",
        "  ```\n",
        "\n",
        "### **Extra Examples:**\n",
        "\n",
        "1. **Aggregation: Mean, Median, Sum:**\n",
        "   ```python\n",
        "   print(\"Mean of Column1:\", df['Column1'].mean())\n",
        "   print(\"Median of Column1:\", df['Column1'].median())\n",
        "   print(\"Sum of Column1:\", df['Column1'].sum())\n",
        "   ```\n",
        "2. **Count distinct values using `nunique()`:**\n",
        "   ```python\n",
        "   print(\"Distinct values in Column2:\", df['Column2'].nunique())\n",
        "   ```\n",
        "3. **Grouping Data:**\n",
        "   ```python\n",
        "   # Group by a column (if you had categorical data)\n",
        "   # For demonstration, assume a new column 'Category'\n",
        "   df['Category'] = [\"A\", \"B\", \"A\", \"B\", \"A\"]\n",
        "   grouped = df.groupby(\"Category\")[\"Column1\"].mean()\n",
        "   print(\"Average Column1 by Category:\\n\", grouped)\n",
        "   ```\n",
        "4. **Applying custom functions:**\n",
        "   ```python\n",
        "   # Apply a lambda function to modify a column\n",
        "   df[\"Column1_plus_10\"] = df[\"Column1\"].apply(lambda x: x + 10)\n",
        "   print(\"DataFrame after applying lambda:\\n\", df)\n",
        "   ```\n",
        "\n",
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "- **Pandas DataFrames** allow you to work with structured, tabular data efficiently.\n",
        "- **Series** (a single column of data) are useful for one-dimensional data.\n",
        "- Basic methods like **head(), tail(), info(), describe()** provide quick insights into your data.\n",
        "- Indexing with **loc** (label-based) and **iloc** (integer-based) lets you access data in flexible ways.\n",
        "- Converting DataFrames into NumPy arrays can be useful for computations.\n",
        "- **Basic operations** including handling missing data, aggregation, and filtering are essential for Exploratory Data Analysis (EDA) and Machine Learning.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "4pG_iCbsPc6H"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ARxpMP-NO-Fp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_79J5NlKLV8d"
      },
      "outputs": [],
      "source": []
    }
  ]
}